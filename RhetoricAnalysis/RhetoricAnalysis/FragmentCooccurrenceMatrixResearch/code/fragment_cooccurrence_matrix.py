import json
import csv
import time
import collections
import os
import matplotlib.pyplot as plot
from convokit import Corpus, QuestionTypology


class FragmentCooccurrenceMatrix:
    """
    Class for generating the cooccurrence matrix from the files generated by the Cornell Conversational Analysis
    Toolkit (CCAT).

    Provides 4 class methods for generating a matrix:
    - from_previous_matrix_files: Used when a previously written to file matrix should be reused
    - from_full_ccat_run: Used when no CCAT files exist for the corpus so a CCAT run is necessary to construct the
      cooccurrence matrix
    - from_ccat_files: Used when CCAT has already been run previously so the files required already exist
    - test_matrix: Generates a matrix that can be used for testing, the specification for which can be found in the
      dissertation for this work

    Attributes:
    - cooccurrence_matrix: The 2D array representing the cooccurrence matrix where rows are question fragments and
      columns are answer fragments
    - minimum_fragment_occurrence_frequency: The minimum number of times answer and question fragments must occur to be
      retained
    - unique_question_fragments_and_ids:  A dictionary mapping each question fragment to its unique id, which is also
      its row number
    - ids_to_unique_question_fragments: A dictionary mapping each id / row number to a unique question fragments
    - unique_answer_fragments_and_ids: A dictionary mapping each question fragment to its unique id, which is also
      its column number
    - ids_to_unique_answer_fragments: A dictionary mapping each id / column number to a unique question fragments
    - question_fragment_frequencies_greater_than_limit: A dictionary mapping every question fragment that occurred the
      minimum number of times to its occurrence frequency
    - answer_fragment_frequencies_greater_than_limit: A dictionary mapping every answer fragment that occurred the
      minimum number of times to its occurrence frequency
    - total_cooccurrances: The sum of all elements in the cooccurrence matrix
    - stop_words: The set of all stop words to consider
    """

    cooccurrence_matrix = None
    minimum_fragment_occurrence_frequency = 1
    unique_question_fragments_and_ids = None
    ids_to_unique_question_fragments = None
    unique_answer_fragments_and_ids = None
    ids_to_unique_answer_fragments = None
    question_fragment_frequencies_greater_than_limit = None
    answer_fragment_frequencies_greater_than_limit = None
    total_cooccurrances = 0
    stop_words = None

    @classmethod
    def from_previous_matrix_files(cls, matrix_filepath, question_fragments_filepath, answer_fragments_filepath,
                                   verbose=False):
        """
        Builds the co occurrence matrix from the output files of a previous run to reduce construction time

        :param matrix_filepath: The file path of the matrix csv file
        :param question_fragments_filepath: The file path of the question fragments csv file containing ID and frequency
        :param answer_fragments_filepath: The file path of the answer fragments csv file containing ID and frequency
        :param verbose: If true then details of the running procedure and printed to the console
        :return: A reference to this object now properly populated and constructed
        :raises ValueError: Only raised if crucial parameters are missing
        """

        if matrix_filepath is None:
            raise ValueError('matrix_filepath cannot be None')
        elif question_fragments_filepath is None:
            raise ValueError('question_fragments_filepath cannot be None')
        elif answer_fragments_filepath is None:
            raise ValueError('answer_fragments_filepath cannot be None')

        # Record start time
        start = time.time()

        cls.total_cooccurrances = 0
        cls.cooccurrence_matrix = []
        cls.unique_question_fragments_and_ids = {}
        cls.unique_answer_fragments_and_ids = {}
        cls.ids_to_unique_answer_fragments = {}
        cls.ids_to_unique_question_fragments = {}
        cls.question_fragment_frequencies_greater_than_limit = {}
        cls.answer_fragment_frequencies_greater_than_limit = {}

        if verbose:
            print("Matrix file: {}".format(matrix_filepath))
            print("Question Fragments file: {}".format(question_fragments_filepath))
            print("Answer Fragments file: {}".format(answer_fragments_filepath))

        # Open the matrix file and add each row to the co occurrence matrix
        with open(matrix_filepath) as matrix_file:
            read_csv = csv.reader(matrix_file, delimiter=',')
            for row in read_csv:
                int_row = [int(numeric_string) for numeric_string in row]
                # Assert that no value is less than 0 as that is an impossible value
                for int_value in int_row:
                    assert int_value >= 0
                # Assertion passed for this row
                cls.total_cooccurrances += sum(int_row)
                cls.cooccurrence_matrix.append(int_row)
            matrix_file.close()

        # Open the question fragments file and populate the relevant maps
        with open(question_fragments_filepath) as question_fragment_file:
            read_csv = csv.reader(question_fragment_file, delimiter=',')
            # Skip headers
            next(read_csv, None)
            for row in read_csv:
                cls.unique_question_fragments_and_ids[row[0]] = int(row[1])
                cls.question_fragment_frequencies_greater_than_limit[row[0]] = int(row[2])
            question_fragment_file.close()

        # Open the answer fragments file and populate the relevant maps
        with open(answer_fragments_filepath) as answer_fragment_file:
            read_csv = csv.reader(answer_fragment_file, delimiter=',')
            # Skip headers
            next(read_csv, None)
            for row in read_csv:
                cls.unique_answer_fragments_and_ids[row[0]] = int(row[1])
                cls.answer_fragment_frequencies_greater_than_limit[row[0]] = int(row[2])
            answer_fragment_file.close()

        # Create the ID to fragment maps by reversing the mappings of the fragment to ID maps
        cls.ids_to_unique_question_fragments = {v: k for k, v in cls.unique_question_fragments_and_ids.items()}
        cls.ids_to_unique_answer_fragments = {v: k for k, v in cls.unique_answer_fragments_and_ids.items()}

        # Record the end time
        end = time.time()

        if verbose:
            print("Matrix building complete in {} seconds".format(end - start))
            print("Number of Answer Fragments: {}".format(len(cls.answer_fragment_frequencies_greater_than_limit)))
            print("Number of Question Fragments: {}".format(len(cls.question_fragment_frequencies_greater_than_limit)))
            print("Total Co-occurrences: {}".format(cls.total_cooccurrances))
            print("Number of Cells: {}".format(
                len(cls.question_fragment_frequencies_greater_than_limit) *
                len(cls.answer_fragment_frequencies_greater_than_limit)))
            print("Answer Fragment to Question Fragment Ratio: {}".format(
                len(cls.answer_fragment_frequencies_greater_than_limit) /
                len(cls.question_fragment_frequencies_greater_than_limit)))

        return cls()

    @classmethod
    def test_matrix(cls):
        """
        Used to construct a test matrix with known dimensions and values for unit tests. The specification of the
        test matrix is given in the dissertation.

        :return: A reference to this object constructed as a test matrix
        """

        cls.total_cooccurrances = 214
        cls.unique_question_fragments_and_ids = {'v': 0, 'w': 1, 'x': 2, 'y': 3, 'z': 4}
        cls.ids_to_unique_question_fragments = {0: 'v', 1: 'w', 2: 'x', 3: 'y', 4: 'z'}
        cls.unique_answer_fragments_and_ids = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}
        cls.ids_to_unique_answer_fragments = {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e'}
        cls.question_fragment_frequencies_greater_than_limit = {'v': 40, 'w': 100, 'x': 20, 'y': 10, 'z': 5}
        cls.answer_fragment_frequencies_greater_than_limit = {'a': 25, 'b': 50, 'c': 15, 'd': 7, 'e': 8}
        cls.cooccurrence_matrix = [
            [12, 11, 10, 14, 20],
            [7, 11, 7, 8, 4],
            [3, 1, 0, 0, 10],
            [17, 16, 15, 16, 17],
            [0, 3, 5, 0, 7],
        ]
        return cls()

    @classmethod
    def from_full_ccat_run(cls, dataset_name, dataset_file_extension, num_clusters, random_seed,
                           minimum_fragment_occurrence_frequency=1, verbose=False, stop_words_filename=None,
                           remove_single_word_fragments=False, ccat_verbose=False):
        """
        Performs a CCAT run on the given dataset and then construct the co occurrence matrix using 'from_ccat_files'.
        This code expects the dataset to be in the same directory as this code.

        :param dataset_name: The name of the dataset to be used when searching for it and then naming the CCAT output
                             folders
        :param dataset_file_extension: The file extension to be used when searching for the dataset e.g .json
        :param num_clusters: The number of clusters to be used by the CCAT
        :param random_seed: The random seed to be used by the CCAT
        :param remove_single_word_fragments: Boolean indicating whether to remove fragments consisting of a single word
        :param minimum_fragment_occurrence_frequency: The minimum number of times a fragment must occur to be considered
        :param verbose: If true then details of the running procedure and printed to the console
        :param stop_words_filename: If passed any fragment that is only a stop word will not be considered
        :param ccat_verbose: If true then CCAT details will be printed to the console (this is very verbose)
        :return: A reference to this object now properly populated and constructed
        :raises ValueError: Only raised if crucial parameters are missing
        """

        if dataset_name is None:
            raise ValueError('dataset_name cannot be None')
        elif dataset_file_extension is None:
            raise ValueError('dataset_file_extension cannot be None')

        start = time.time()
        current_directory = os.getcwd()
        dataset_file_path = os.path.join(current_directory, "{}{}".format(dataset_name, dataset_file_extension))

        if verbose:
            print("Current directory: {}".format(current_directory))
            print("Dataset filepath: {}".format(dataset_file_path))
            print("Beginning CCAT run")

        corpus = Corpus(filename=dataset_file_path)
        QuestionTypology(corpus=corpus, data_dir=current_directory, dataset_name=dataset_name,
                         num_clusters=num_clusters, verbose=ccat_verbose, random_seed=random_seed, skip_clustering=True)

        end = time.time()

        if verbose:
            print("CCAT run finished in {} seconds".format(end - start))

        # At this point the directories required for the matrix will have been created
        answer_arcs_filepath = os.path.join(current_directory, "{}{}".format(dataset_name, "-motifs"),
                                            "answer_arcs.json")
        question_arcs_filepath = os.path.join(current_directory, "{}{}".format(dataset_name, "-motifs"),
                                              "question_arcs.json")

        if verbose:
            print("Answer arcs filepath: {}".format(answer_arcs_filepath))
            print("Question arcs filepath: {}".format(question_arcs_filepath))

        return cls.from_ccat_files(answer_arcs_filename=answer_arcs_filepath,
                                   question_arcs_filename=question_arcs_filepath,
                                   minimum_fragment_occurrence_frequency=minimum_fragment_occurrence_frequency,
                                   verbose=verbose,
                                   stop_words_filename=stop_words_filename,
                                   remove_single_word_fragments=remove_single_word_fragments)

    @classmethod
    def from_ccat_files(cls, answer_arcs_filename, question_arcs_filename,
                        minimum_fragment_occurrence_frequency=1, verbose=False, stop_words_filename=None,
                        remove_single_word_fragments=False):
        """
        Build the co occurrence matrix from files previously output by the CCAT

        :param answer_arcs_filename: File path for the file named 'answer_fragments.csv' from the CCAT
        :param question_arcs_filename: File path for the file named 'question_fragments.csv' from the CCAT
        :param minimum_fragment_occurrence_frequency: The minimum number of times a fragment must occur to be considered
        :param verbose: If true then details of the running procedure and printed to the console
        :param stop_words_filename: If passed any fragment that is only a stop word will not be considered
        :param remove_single_word_fragments: If passed fragments containing only a single word will not be considered
        :return: A reference to this object now properly populated and constructed
        :raises ValueError: Only raised if crucial parameters are missing
        """

        if answer_arcs_filename is None:
            raise ValueError('answer_arcs_filename cannot be None')
        elif question_arcs_filename is None:
            raise ValueError('question_arcs_filename cannot be None')

        # Record start time
        start = time.time()

        cls.total_cooccurrances = 0
        cls.minimum_fragment_occurrence_frequency = minimum_fragment_occurrence_frequency
        cls.unique_question_fragments_and_ids = {}
        cls.unique_answer_fragments_and_ids = {}
        cls.ids_to_unique_answer_fragments = {}
        cls.ids_to_unique_question_fragments = {}
        cls.stop_words = set()

        answer_arc_objects = {}
        question_arc_objects = {}
        stop_word_removals = 0

        if verbose:
            print("Using minimum fragment frequency limit of {}".format(minimum_fragment_occurrence_frequency))
            print("Question arcs file: {}".format(question_arcs_filename))
            print("Answer arcs file: {}".format(answer_arcs_filename))
            print("Stop words file: {}".format(stop_words_filename))
            print("Removing single word fragments: {}".format(remove_single_word_fragments))

        # If the caller wants us to remove stop words defined by a file then populate the set of stop words
        if stop_words_filename is not None:
            with open(stop_words_filename) as stop_words_lines:
                for line in stop_words_lines:
                    line = line.replace("\n", "")
                    # There are multiple forms a fragment only containing the stop word could take, so add them all
                    cls.stop_words.add(line)
                    cls.stop_words.add("{}{}".format(line, ">*"))
                    cls.stop_words.add("{}{}".format(line, "_*"))
                stop_words_lines.close()

        with open(answer_arcs_filename) as answer_arcs:
            for answer_line in answer_arcs:
                answer_object = json.loads(answer_line)
                # The next 3 lines remove the 'span...' ending to the pair_idx as we want to consider entire q-a pairs
                pair_idx = answer_object['pair_idx']
                index = pair_idx.index('span')
                pair_idx = pair_idx[:index]

                # If we haven't seen this pair_idx before make the array for it
                if answer_arc_objects.get(pair_idx, None) is None:
                    answer_arc_objects[pair_idx] = []

                for answer_fragment in answer_object['arcs']:
                    if answer_fragment in cls.stop_words or cls.is_composite_stop_word_fragment(cls.stop_words, answer_fragment):
                        stop_word_removals += 1
                        continue
                    if remove_single_word_fragments and \
                            FragmentCooccurrenceMatrix.is_single_word_fragment(answer_fragment):
                        continue

                    answer_arc_objects[pair_idx].append(answer_fragment)
            answer_arcs.close()

        with open(question_arcs_filename) as question_arcs:
            for question_line in question_arcs:
                question_object = json.loads(question_line)
                # The next 3 lines remove the 'span...' ending to the pair_idx as we want to consider entire q-a pairs
                pair_idx = question_object['pair_idx']
                index = pair_idx.index('span')
                pair_idx = pair_idx[:index]

                # If we haven't seen this pair_idx before make the array for it
                if question_arc_objects.get(pair_idx, None) is None:
                    question_arc_objects[pair_idx] = []

                for question_fragment in question_object['arcs']:
                    if question_fragment in cls.stop_words or cls.is_composite_stop_word_fragment(cls.stop_words, question_fragment):
                        stop_word_removals += 1
                        continue
                    if remove_single_word_fragments and \
                            FragmentCooccurrenceMatrix.is_single_word_fragment(question_fragment):
                        continue

                    question_arc_objects[pair_idx].append(question_fragment)
            question_arcs.close()

        if verbose:
            print("File reading complete, beginning data cleaning and co occurrence matrix building")

        # The intersection gives us the pairs
        question_answer_pair_ids = set(question_arc_objects.keys()).intersection(set(answer_arc_objects.keys()))

        if verbose:
            print("{} pairs before removals".format(len(question_answer_pair_ids)))

        # Remove pairs where there are no question fragments or no answer fragments because we cannot co-occur with
        # nothing
        removals = []
        for pair_id in question_answer_pair_ids.copy():
            if len(question_arc_objects[pair_id]) == 0 or len(answer_arc_objects[pair_id]) == 0:
                removals.append(pair_id)
                question_answer_pair_ids.remove(pair_id)

        if verbose:
            print("{} pair ids were removed due to having no answer or question fragments to operate on"
                  .format(len(removals)))
            print("{} pairs after removal".format(len(question_answer_pair_ids)))

        question_fragment_frequencies = {}
        answer_fragment_frequencies = {}

        # Now go over the pair_ids with removals taken out and calculate frequencies
        for pair_id in question_answer_pair_ids:
            for question_fragment in question_arc_objects[pair_id]:
                if question_fragment_frequencies.get(question_fragment, None) is None:
                    question_fragment_frequencies[question_fragment] = 0
                question_fragment_frequencies[question_fragment] += 1

            for answer_fragment in answer_arc_objects[pair_id]:
                if answer_fragment_frequencies.get(answer_fragment, None) is None:
                    answer_fragment_frequencies[answer_fragment] = 0
                answer_fragment_frequencies[answer_fragment] += 1

        cls.question_fragment_frequencies_greater_than_limit = {}
        cls.answer_fragment_frequencies_greater_than_limit = {}
        current_question_fragment_id = 0
        current_answer_fragment_id = 0

        for fragment in question_fragment_frequencies:
            # If the value exceeds the limit keep it and assign it an id
            if question_fragment_frequencies[fragment] >= minimum_fragment_occurrence_frequency:
                cls.question_fragment_frequencies_greater_than_limit[fragment] = question_fragment_frequencies[
                    fragment]
                cls.unique_question_fragments_and_ids[fragment] = current_question_fragment_id
                current_question_fragment_id += 1

        for fragment in answer_fragment_frequencies:
            if answer_fragment_frequencies[fragment] >= minimum_fragment_occurrence_frequency:
                cls.answer_fragment_frequencies_greater_than_limit[fragment] = answer_fragment_frequencies[fragment]
                cls.unique_answer_fragments_and_ids[fragment] = current_answer_fragment_id
                current_answer_fragment_id += 1

        # Assert 0 -> (minimum_fragment_occurrence_frequency-1) do not occur in the values of the trimmed frequencies
        for i in range(0, minimum_fragment_occurrence_frequency):
            assert i not in cls.answer_fragment_frequencies_greater_than_limit.values()
            assert i not in cls.question_fragment_frequencies_greater_than_limit.values()

        # Assert each of the fragments above the minimum_fragment_occurrence_frequency have an id
        assert len(cls.answer_fragment_frequencies_greater_than_limit) == len(cls.unique_answer_fragments_and_ids)
        assert len(cls.question_fragment_frequencies_greater_than_limit) == len(cls.unique_question_fragments_and_ids)

        num_rows = len(cls.unique_question_fragments_and_ids)
        num_columns = len(cls.unique_answer_fragments_and_ids)

        cls.ids_to_unique_question_fragments = {v: k for k, v in cls.unique_question_fragments_and_ids.items()}
        cls.ids_to_unique_answer_fragments = {v: k for k, v in cls.unique_answer_fragments_and_ids.items()}

        # Initialise the matrix (filled with 0's)
        cls.cooccurrence_matrix = [[0 for x in range(num_columns)] for y in range(num_rows)]

        # Fill the matrix with co-occurrence frequencies
        for pair_id in question_answer_pair_ids:
            for question_fragment in question_arc_objects[pair_id]:
                question_id_for_row_index = cls.unique_question_fragments_and_ids.get(question_fragment, None)

                if question_id_for_row_index is None:
                    # If there is no question_fragment id then we can skip the inner loop entirely
                    # This occurs when the question_fragment did not have the minimum frequency required
                    # and so was not assigned an ID
                    continue

                for answer_fragment in answer_arc_objects[pair_id]:
                    answer_id_for_column_index = cls.unique_answer_fragments_and_ids.get(answer_fragment, None)

                    if answer_id_for_column_index is None:
                        # If there is no answer fragment id we can skip this inner loop iteration
                        # This occurs when the answer_fragment did not have the minimum frequency required
                        # and so was not assigned an ID
                        continue

                    cls.cooccurrence_matrix[question_id_for_row_index][answer_id_for_column_index] += 1
                    cls.total_cooccurrances += 1

        # Record the end time
        end = time.time()

        if verbose:
            print("Matrix building complete in {} seconds".format(end - start))
            print("Stop word removals: {}".format(stop_word_removals))
            print("Number of Answer Fragments: {}".format(len(cls.answer_fragment_frequencies_greater_than_limit)))
            print("Number of Question Fragments: {}".format(len(cls.question_fragment_frequencies_greater_than_limit)))
            print("Total Co-occurrences: {}".format(cls.total_cooccurrances))
            print("Number of Cells: {}".format(
                len(cls.question_fragment_frequencies_greater_than_limit) *
                len(cls.answer_fragment_frequencies_greater_than_limit)))
            print("Answer Fragment to Question Fragment Ratio: {}".format(
                len(cls.answer_fragment_frequencies_greater_than_limit) /
                len(cls.question_fragment_frequencies_greater_than_limit)))

        return cls()

    def write_matrix_to_files(self):
        """
        Creates 3 files, 1 for the matrix, 1 for the question fragment details and 1 for answer fragment details.
        These are the files which can be used to rebuild a matrix.
        """
        with open("output/fragment_cooccurrence_matrix.csv", "w", newline='') as f:
            writer = csv.writer(f)
            writer.writerows(self.cooccurrence_matrix)
            f.close()

        with open("output/question_fragments.csv", "w") as f:
            f.write("Question Fragment, ID, Frequency")
            f.write('\n')
            for question_fragment in self.unique_question_fragments_and_ids:
                f.write("{},{},{}".format(question_fragment, self.unique_question_fragments_and_ids[question_fragment],
                                          self.question_fragment_frequencies_greater_than_limit[question_fragment]))
                f.write('\n')
            f.close()

        with open("output/answer_fragments.csv", "w") as f:
            f.write("Answer Fragment, ID, Frequency")
            f.write('\n')
            for answer_fragment in self.unique_answer_fragments_and_ids:
                f.write("{},{},{}".format(answer_fragment, self.unique_answer_fragments_and_ids[answer_fragment],
                                          self.answer_fragment_frequencies_greater_than_limit[answer_fragment]))
                f.write('\n')
            f.close()

    def get_number_of_question_fragments(self):
        """Return the number of question fragments in the matrix"""
        return len(self.question_fragment_frequencies_greater_than_limit)

    def get_number_of_answer_fragments(self):
        """Return the number of question fragments in the matrix"""
        return len(self.answer_fragment_frequencies_greater_than_limit)

    def get_question_fragment_id(self, question_fragment):
        """
        Return the ID of the question_fragment param or None if it is not present

        :param question_fragment: The question fragment to return the ID of
        :return: Integer ID or None
        """
        return self.unique_question_fragments_and_ids.get(question_fragment, None)

    def get_answer_fragment_id(self, answer_fragment):
        """
        Return the ID of the answer_fragment param or None if it is not present

        :param answer_fragment: The answer fragment to return the ID of
        :return: Integer ID or None
        """
        return self.unique_answer_fragments_and_ids.get(answer_fragment, None)

    def get_question_fragment_occurrence_frequency(self, question_fragment):
        """
        Return the occurrence frequency of the question_fragment param or None if it is not present

        :param question_fragment: The question fragment to return the occurrence frequency of
        :return: Integer occurrence frequency or None
        """
        return self.question_fragment_frequencies_greater_than_limit.get(question_fragment, None)

    def get_answer_fragment_occurrence_frequency(self, answer_fragment):
        """
        Return the occurrence frequency of the answer_fragment param or None if it is not present

        :param answer_fragment: The answer fragment to return the occurrence frequency of
        :return: Integer occurrence frequency or None
        """
        return self.answer_fragment_frequencies_greater_than_limit.get(answer_fragment, None)

    def get_question_fragment_total_cooccurrence_frequency(self, question_fragment):
        """
        Return the total co occurrence frequency of the question_fragment param

        :param question_fragment: The question fragment to return the total co occurrence frequency of
        :return: Integer total co occurrence frequency
        """
        all_cooccurrence_freqs = self.get_all_coocurrence_frequencies_for_question_fragment(question_fragment)
        return sum(all_cooccurrence_freqs) if all_cooccurrence_freqs is not None else None

    def get_answer_fragment_total_cooccurrence_frequency(self, answer_fragment):
        """
        Return the total co occurrence frequency of the answer_fragment param

        :param answer_fragment: The answer fragment to return the total co occurrence frequency of
        :return: Integer total co occurrence frequency
        """
        all_cooccurrence_freqs = self.get_all_coocurrence_frequencies_for_answer_fragment(answer_fragment)
        return sum(all_cooccurrence_freqs) if all_cooccurrence_freqs is not None else None

    def get_cooccurrence_frequency(self, question_fragment, answer_fragment):
        """
        Return the absolute frequency of co occurrence for the question_fragment and answer_fragment pair, or None

        :param question_fragment: The question fragment component of the pair
        :param answer_fragment: The answer fragment component of the pair
        :return: Integer co occurrence frequency for the pair of fragments, or None
        """
        answer_fragment_id = self.unique_answer_fragments_and_ids.get(answer_fragment, None)
        question_fragment_id = self.unique_question_fragments_and_ids.get(question_fragment, None)

        # If either the answer or question fragment doesn't exist in our matrix then return None
        if answer_fragment_id is None or question_fragment_id is None:
            return None
        else:
            return self.cooccurrence_matrix[question_fragment_id][answer_fragment_id]

    def get_question_fragment_for_row(self, row_number):
        """
        Return the question fragment for the row_number in the matrix, or None if row doesn't exist

        :param row_number: The row number for which to determine the question fragment
        :return: The question fragment corresponding to the row_number, or None
        """
        return self.ids_to_unique_question_fragments.get(row_number, None)

    def get_answer_fragment_for_column(self, column_number):
        """
        Return the answer fragment for the column_number in the matrix, or None if column doesn't exist

        :param column_number: The column number for which to determine the answer fragment
        :return: The answer fragment corresponding to the column_number, or None
        """
        return self.ids_to_unique_answer_fragments.get(column_number, None)

    def get_all_coocurrence_frequencies_for_question_fragment(self, question_fragment):
        """
        Return the array of absolute co occurrence frequencies for the given question_fragment, or None

        :param question_fragment: The question fragment for which to get the co occurrence frequencies array
        :return: Array of integer co occurrence frequencies for the question fragment, or None
        """
        row = self.get_question_fragment_id(question_fragment)
        if row is None:
            return None
        else:
            return self.cooccurrence_matrix[row]

    def get_all_coocurrence_frequencies_for_answer_fragment(self, answer_fragment):
        """
        Return the array of absolute co occurrence frequencies for the given answer_fragment, or None

        :param answer_fragment: The answer fragment for which to get the co occurrence frequencies array
        :return: Array of integer co occurrence frequencies for the answer fragment, or None
        """
        column = self.get_answer_fragment_id(answer_fragment)
        if column is None:
            return None
        else:
            return [row[column] for row in self.cooccurrence_matrix]

    def get_summed_cooccurrence_frequencies_for_fragment_list(self, list_of_fragments, question_fragments=True):
        """
        Return the array of co occurrence frequencies derived from summing the co occurrence frequency arrays
        element by element for the fragments in the list given.

        For example:
            input fragments are ('fragment_x', 'fragment_y')
            fragment_x gives (100, 200, 400)
            fragment_y gives (50, 100, 200)
            output is (150, 300, 600)

        :param list_of_fragments: The list of answer or question fragments to compute the summed co occurrence
                                  frequencies for
        :param question_fragments: Boolean indicating whether to treat the input list as question fragments or answer
                                   fragments
        :return: { 'in_matrix': The list of summed co occurrence frequencies,
                   'not_in_matrix': The fragments not in matrix }
        """

        summed_frequencies = []
        fragments_not_in_matrix = []
        for fragment in list_of_fragments:
            if question_fragments:
                frequencies_for_fragment = \
                    self.get_all_coocurrence_frequencies_for_question_fragment(fragment)
            else:
                frequencies_for_fragment = \
                    self.get_all_coocurrence_frequencies_for_answer_fragment(fragment)

            if frequencies_for_fragment is None:
                fragments_not_in_matrix.append(fragment)
                continue

            if len(summed_frequencies) == 0:
                # We must copy the first frequency list so we have something to add to
                summed_frequencies = list(frequencies_for_fragment)
            else:
                # We have done the initial copy, now add to all elements of the summed array
                for i in range(0, len(frequencies_for_fragment)):
                    summed_frequencies[i] += frequencies_for_fragment[i]

        return {'in_matrix': summed_frequencies, 'not_in_matrix': fragments_not_in_matrix}

    def get_summed_relative_cooccurrence_frequencies_for_fragment_list(self,
                                                                       list_of_fragments,
                                                                       question_fragments=True):
        """
        Return get_summed_cooccurrence_frequencies_for_fragment_list converted to relative frequencies

        :param list_of_fragments: The list of answer or question fragments to compute the summed relative co occurrence
                                  frequencies for
        :param question_fragments: Boolean indicating whether to treat the input list as question fragments or answer
                                   fragments
        :return: { 'in_matrix': The list of summed relative co occurrence frequencies,
                   'not_in_matrix': The fragments not in matrix }
        """
        absolute_frequencies_map = self.get_summed_cooccurrence_frequencies_for_fragment_list(
            list_of_fragments,
            question_fragments=question_fragments)

        relative_frequencies = [float(absolute_freq) / self.total_cooccurrances * 100
                                for absolute_freq in absolute_frequencies_map['in_matrix']]

        return {'in_matrix': relative_frequencies, 'not_in_matrix': absolute_frequencies_map['not_in_matrix']}

    def get_defined_number_of_greatest_fragments_for_fragment_list(self, list_of_fragments, limit=5, relative=False,
                                                                   question_fragments=True):
        """
        Given a list of question fragments this method will return the most frequently co occurring answer fragments,
        and vice versa.

        Given a list of fragments this method will use get_summed_cooccurrence_frequencies_for_fragment_list or
        get_summed_relative_cooccurrence_frequencies_for_fragment_list to get the summed lists for the fragment list, it
        will then find the top 'x' frequencies where 'x' is defined by the 'limit' parameter. These are returned in an
        OrderedDict in descending order where K => V pairs are as such: 'fragment_x' => 1000, in the map with key
        'in_matrix'.

        :param list_of_fragments: The list of fragments to find the greatest co occurring fragments for
        :param limit: The number of most frequent fragments to return, default value of 5
        :param relative: Whether to use and return relative co occurring frequencies
        :param question_fragments: Boolean indicating whether to treat the input list as question fragments or answer
                                   fragments
        :return: { 'in_matrix': OrderedDict in descending order in the form 'fragment_x' => 1000,
                   'not_in_matrix': The fragments not in matrix }
        """

        if relative:
            frequencies_for_list_map = self.get_summed_relative_cooccurrence_frequencies_for_fragment_list(
                list_of_fragments,
                question_fragments=question_fragments)
        else:
            frequencies_for_list_map = self.get_summed_cooccurrence_frequencies_for_fragment_list(
                list_of_fragments,
                question_fragments=question_fragments)

        frequencies_for_list = list(frequencies_for_list_map['in_matrix'])

        # Use an ordered dict which orders based on sequence of input, which for us is max -> min
        fragment_to_frequency_map_ordered = collections.OrderedDict()

        # For 0 -> (limit-1) get the max value in the list, find which answer fragment has the highest
        # co occurrence frequency, add it and it's relative frequency to the ordered dict then remove it
        # from the list so it is not repeated and the next highest will be retrieved in the next loop iteration
        for i in range(0, limit):
            # Get the most frequent fragment frequency
            current_most_frequent_fragment_frequency = max(frequencies_for_list)
            # Get the index of the highest frequency
            current_most_frequent_fragment_index = \
                frequencies_for_list.index(current_most_frequent_fragment_frequency)

            # Get the fragment for the index (which is the column of the fragment)
            if question_fragments:
                current_most_frequent_fragment = self.get_answer_fragment_for_column(
                    current_most_frequent_fragment_index)
            else:
                current_most_frequent_fragment = self.get_question_fragment_for_row(
                    current_most_frequent_fragment_index)

            # Add the answer_fragment -> frequency mapping to the ordered dict
            fragment_to_frequency_map_ordered[current_most_frequent_fragment] = current_most_frequent_fragment_frequency
            # We cannot remove a value as that changes all the indexes after it which will lead to the wrong fragments
            # being identified so set it to -1 as this is an impossible frequency
            frequencies_for_list[current_most_frequent_fragment_index] = -1

        return {'in_matrix': fragment_to_frequency_map_ordered,
                'not_in_matrix': frequencies_for_list_map['not_in_matrix']}

    @staticmethod
    def get_fragments_for_unseen_inputs(unseen_question, unseen_answer, num_clusters, ccat_verbose, random_seed):
        """
        Using the CCAT get the question fragments for the passed unseen question text.

        This method uses a file containing a single question-answer pair, replaces the texts with the passed
        texts, saves the file and then passes it to the CCAT as the corpus. The CCAT output files for
        the question and answers arcs are then parsed and the fragments returned.

        :param unseen_question: The string question to get the fragments for, or None
        :param unseen_answer: The string answer to get the fragments for, or None
        :param num_clusters: The number of clusters param for the CCAT
        :param ccat_verbose: The verbose param for the CCAT
        :param random_seed: The random seed param for the CCAT
        :return: {'question_fragments': Array of question fragments, 'answer_fragments': Array of answer fragments}
        """

        current_dir = os.getcwd()
        dataset_name = 'single-q-a-pair'
        single_q_a_pair_filepath = os.path.join(current_dir, '..\\resources', "{}.json".format(dataset_name))
        question_arcs_filepath = os.path.join(current_dir, "{}{}".format(dataset_name, "-motifs"), "question_arcs.json")
        answer_arcs_filepath = os.path.join(current_dir, "{}{}".format(dataset_name, "-motifs"), "answer_arcs.json")
        array_to_write = []

        # Open the file, swap in our text and fill the array to write
        with open(single_q_a_pair_filepath, 'r') as single_q_a_pair_file:
            pair_array = json.load(single_q_a_pair_file)
            # Find the question, and replace it's text
            for json_object in pair_array:
                if json_object['is_question'] and unseen_question is not None:
                    json_object['text'] = unseen_question
                if json_object['is_answer'] and unseen_answer is not None:
                    json_object['text'] = unseen_answer
                array_to_write.append(json_object)
            single_q_a_pair_file.close()

        # Write the array with the question now altered back to the same file
        with open(single_q_a_pair_filepath, 'w') as output:
            json.dump(array_to_write, output, indent=4)
            output.close()

        # Set up the corpus
        corpus = Corpus(filename=single_q_a_pair_filepath)

        # We can ignore the error which occurs during the clustering phase of the CCAT since we have the output
        # files we need by that point
        QuestionTypology(corpus=corpus, data_dir=current_dir, dataset_name=dataset_name, num_clusters=num_clusters,
                         verbose=ccat_verbose, random_seed=random_seed, skip_clustering=True)

        unseen_question_fragments = []
        with open(question_arcs_filepath) as question_arcs:
            for question_line in question_arcs:
                question_object = json.loads(question_line)
                for question_fragment in question_object['arcs']:
                    unseen_question_fragments.append(question_fragment)
            question_arcs.close()

        unseen_answer_fragments = []
        with open(answer_arcs_filepath) as answer_arcs:
            for answer_line in answer_arcs:
                answer_object = json.loads(answer_line)
                for answer_fragment in answer_object['arcs']:
                    unseen_answer_fragments.append(answer_fragment)
            answer_arcs.close()

        return {'question_fragments': unseen_question_fragments, 'answer_fragments': unseen_answer_fragments}

    def get_defined_number_of_greatest_answer_fragments_for_unseen_question(self, unseen_question, num_clusters,
                                                                            ccat_verbose, random_seed, limit=5):
        """
        Return the caller defined number of most frequently co occurring fragments for the question text given

        :param unseen_question: String representing the question we have not seen in the corpus before
        :param num_clusters: The number of clusters param for the CCAT
        :param ccat_verbose: The verbose param for the CCAT
        :param random_seed: The random seed param for the CCAT
        :param limit: How many answer fragments to return
        :return: { 'in_matrix': OrderedDict in descending order in the form 'fragment_x' => 1000,
                   'not_in_matrix': The question fragments from the unseen question not in matrix }
        """
        question_fragments_for_question = self.get_fragments_for_unseen_inputs(
            unseen_question, None, num_clusters, ccat_verbose, random_seed)['question_fragments']
        return self.get_defined_number_of_greatest_fragments_for_fragment_list(question_fragments_for_question, limit,
                                                                               False, True)

    def get_defined_number_of_greatest_question_fragments_for_unseen_answer(self, unseen_answer, num_clusters,
                                                                            ccat_verbose, random_seed, limit=5):
        """
        Return the caller defined number of most frequently co occurring fragments for the answer text given. This could
        be used to determine 'given this answer, what was likely to be the question?'

        :param unseen_answer: String representing the answer we have not seen in the corpus before
        :param num_clusters: The number of clusters param for the CCAT
        :param ccat_verbose: The verbose param for the CCAT
        :param random_seed: The random seed param for the CCAT
        :param limit: How many answer fragments to return
        :return: { 'in_matrix': OrderedDict in descending order in the form 'fragment_x' => 1000,
                   'not_in_matrix': The answer fragments from the unseen answer not in matrix }
        """
        answer_fragments_for_answer = self.get_fragments_for_unseen_inputs(
            None, unseen_answer, num_clusters, ccat_verbose, random_seed)['answer_fragments']
        return self.get_defined_number_of_greatest_fragments_for_fragment_list(answer_fragments_for_answer, limit,
                                                                               False, False)

    @staticmethod
    def plot_histogram_for_most_frequently_cooccurring_dict(data_dict, fragments, question_fragments=True):
        """
        Plots a histogram for the OrderedDict returned from a method such as
        get_defined_number_of_greatest_fragments_for_fragment_list or
        get_defined_number_of_greatest_answer_fragments_for_unseen_question

        :param data_dict: A dictionary (probably an OrderedDict) mapping fragments to their co-occurrence frequency
        :param fragments: The fragments that resulted in data_dict being returned from the previous method
        :param question_fragments: Boolean indicating whether the fragments param is question fragments or not
        """
        names = list(data_dict.keys())
        values = list(data_dict.values())
        plot.bar(range(len(data_dict)), values, align='center')
        plot.xticks(range(len(data_dict)), names)
        # Fragment type means what type of fragments are we plotting, so if the fragments param is full of question
        # fragments then what we are plotting will be the answer fragments and vice versa
        fragment_type = "answer" if question_fragments else "question"
        plot.title("{} most co-occurring {} fragments for:\n{}".format(
            len(data_dict), fragment_type, ", ".join(fragments)))
        plot.xlabel("{} Fragments".format(fragment_type.capitalize()))
        plot.ylabel("Summed Cooccurrence Frequency")
        plot.show()

    @staticmethod
    def plot_pie_chart_for_most_frequently_cooccurring_dict(data_dict, fragments, question_fragments=True):
        """
        Plots a histogram for the OrderedDict returned from a method such as
        get_defined_number_of_greatest_fragments_for_fragment_list or
        get_defined_number_of_greatest_answer_fragments_for_unseen_question

        NOTE: The percentages seen in the pie chart represent how much of the top 5 each fragments makes up, not the
        proportion of the total co occurrences it makes up.

        :param data_dict: A dictionary (probably an OrderedDict) mapping fragments to their co-occurrence frequency
        :param fragments: The fragments that resulted in data_dict being returned from the previous method
        :param question_fragments: Boolean indicating whether the fragments param is question fragments or not
        """
        labels = list(data_dict.keys())
        values = list(data_dict.values())
        plot.pie(values, labels=labels, autopct='%1.1f%%')
        plot.axis('equal')
        fragment_type = "answer" if question_fragments else "question"
        plot.title("{} most co-occurring {} fragment proportions for:\n{}".format(
            len(data_dict), fragment_type, ", ".join(fragments)))
        plot.show()

    @staticmethod
    def is_single_word_fragment(fragment):
        """
        Returns whether a fragment contains only a single word

        NOTE: In the fragments that have asterisks they come after the '_' or '>' so we remove them
        this allows us to determine whether a fragment contains only a single word by splitting
        and examining the second array element

        :param fragment: The fragment to be examined
        :return: True if the fragment contains a single word, false otherwise
        """
        frag = fragment.replace("*", "")
        if ">" in frag:
            fragment_components = frag.split(">")
            return fragment_components[1] is ''
        if "_" in fragment:
            fragment_components = frag.split("_")
            return fragment_components[1] is ''

    @staticmethod
    def is_composite_stop_word_fragment(stop_word_list, fragment):
        """
        Returns whether a fragment is made up of StopWord>StopWord or StopWord_StopWord

        :param stop_word_list: The list of stop words to consider
        :param fragment: The fragment to be examined
        :return: True if the fragment is of the form StopWord>StopWord or StopWord_StopWord, false otherwise
        """

        if FragmentCooccurrenceMatrix.is_single_word_fragment(fragment):
            return False

        if ">" in fragment:
            fragment_components = fragment.split(">")
            return fragment_components[0] in stop_word_list and fragment_components[1] in stop_word_list
        if "_" in fragment:
            fragment_components = fragment.split("_")
            return fragment_components[0] in stop_word_list and fragment_components[1] in stop_word_list
